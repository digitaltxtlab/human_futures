rm(list = ls())
library(NLP)
library(tm)
#library(magrittr)
#library(RWeka)
library(slam)
datadir <- "/home/kln/projects/human_futures/human_future_data/txt_vanilla"
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
names(hf.cor) <- gsub("\\..*","",names(hf.cor))
names(hf.cor)
### build basic corpus of HF corpus
rm(list = ls())
library(NLP)
library(tm)
#library(magrittr)
#library(RWeka)
library(slam)
# data directory (vanilla utf-8)
datadir <- "/home/kln/projects/human_futures/human_future_data/txt_vanilla"
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
names(hf.cor) <- gsub("\\..*","",names(hf.cor))# load metadata instead
hf.cor <- tm_map(hf.cor, removePunctuation)
hf.cor <- tm_map(hf.cor, removeNumber)
hf.cor <- tm_map(hf.cor, content_transformer(tolower))
hf.cor <- tm_map(hf.cor, removeWords, stopwords("english"))
hf.cor <- tm_map(hf.cor, stripWhitespace)
### build basic corpus of HF corpus
rm(list = ls())
library(NLP)
library(tm)
#library(magrittr)
#library(RWeka)
library(slam)
# data directory (vanilla utf-8)
datadir <- "/home/kln/projects/human_futures/human_future_data/txt_vanilla"
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
names(hf.cor) <- gsub("\\..*","",names(hf.cor))# load metadata instead
hf.cor <- tm_map(hf.cor, removePunctuation)
hf.cor <- tm_map(hf.cor, removeNumber)
hf.cor <- tm_map(hf.cor, content_transformer(tolower))
datadir <- "/home/kln/projects/human_futures/human_future_data/txt_vanilla"
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
names(hf.cor) <- gsub("\\..*","",names(hf.cor))# load metadata instead
hf.cor <- tm_map(hf.cor, PlainTextDocument)
hf.cor <- tm_map(hf.cor, removePunctuation)
hf.cor <- tm_map(hf.cor, removeNumber)
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
hf.cor <- tm_map(hf.cor, PlainTextDocument)
hf.cor <- tm_map(hf.cor, removePunctuation)
hf.cor <- tm_map(hf.cor, removeNumber)
hf.cor <- tm_map(hf.cor, PlainTextDocument)
datadir <- "/home/kln/projects/human_futures/human_future_data/txt_vanilla"
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
names(hf.cor) <- gsub("\\..*","",names(hf.cor))# load metadata instead
hf.cor <- tm_map(hf.cor, PlainTextDocument)
hf.cor <- tm_map(hf.cor, removePunctuation)
hf.cor <- tm_map(hf.cor, content_transformer(tolower))
hf.cor <- tm_map(hf.cor, removeWords, stopwords("english"))
hf.cor <- tm_map(hf.cor, stripWhitespace)
hf.cor <- tm_map(hf.cor, removeNumbers)
library(RWeka)
hf.dtm <- DocumentTermMatrix(l1_main, control=list(tokenize = NGramTokenizer))
hf.dtm <- DocumentTermMatrix(hf.cor, control=list(tokenize = NGramTokenizer))
ls
ls()
cd()
dir()
getwd()
types.v = unlist(lapply(read.csv("keywords.csv"),as.character),use.names=FALSE)
types.v
types.v = read.csv("keywords.csv")
types.df = read.csv("keywords.csv")
head(types.df)
class.df = read.csv("keywords.csv")
head(class.df)
class.df[,3]
unlist(lapply(class.df[,3],as.character),use.names=FALSE)
type.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
type.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
stopword.v = unlist(lapply(read.csv("stoplist.csv"),as.character),use.names=FALSE)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
# import class and type information (keywords)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
hf.mat <- as.matrix(hf.dtm)
dim(hf.mat)
hf.mat[,1]
hf.mat[1,]
rownames(hf.mat)
rownames(hf.mat) <- names(hf.cor)
hf.mat[1,]
hf.mat[,1]
rownames(hf.mat) <- names(hf.cor)
hf.mat[,1]
rownames(hf.mat)
names(hf.cor)
datadir <- "/home/kln/projects/human_futures/human_future_data/txt_vanilla"
hf.cor <- Corpus(DirSource(datadir, encoding  = "UTF-8"), readerControl = list(language="PlainTextDocument"))
# import document names
names(hf.cor) <- gsub("\\..*","",names(hf.cor))# load metadata instead
names(hf.cor)
rownames(hf.mat) <- names(hf.cor)
hf.mat[,1]
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
types.v[1]
types.v[1]
hf.mat[,types.v[1]]
hf.mat[,cyborg]
hf.mat[,'cyborg']
hf.mat[,'cyborgs']
types.v[1]
types.v[2]
stripWhitespace(types.v)
stripWhitespace(types.v)
types.v
stripWhitespace(types.v)
gsub(" ","",types.v)
gsub(" "*,"",types.v)
gsub(" "+,"",types.v)
gsub(" *","",types.v)
gsub(" ","",types.v)
?gsub
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
gsub(" ","",types.v)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
print(types.v)
gsub(" ","",types.v)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
# remove whitespace and change underscore
types.v <- gsub(" ","",types.v)
types.v <- gsub("_"," ",types.v)
print(types.v)
class.df <- read.csv("keywords.csv")
types.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))
# remove whitespace and change underscore
types.v <- gsub(" ","",types.v)
types.v <- gsub("_"," ",types.v)
print(types.v)
# vector space
hf.dtm <- DocumentTermMatrix(hf.cor, control=list(tokenize = NGramTokenizer))
hf.mat <- as.matrix(hf.dtm)
rownames(hf.mat) <- names(hf.cor)
types.v[2]
hf.mat[,'cyborgs']
hf.mat[,types.v[2]]
hf.mat[,types.v[1]]
hf.mat[,types.v[3]]
hf.mat[,types.v[4]]
hf.mat[,types.v[5]]
hf.mat[,types.v[6]]
