{
    "collab_server" : "",
    "contents" : "### build basic corpus of HF corpus\nrm(list = ls())\n\n# packages\nlibrary(tm)\n#library(RWeka)\n#library(slam)\n\n# data directory (vanilla utf-8)\ndatadir <- \"/home/kln/projects/human_futures/data/plaintext\"\n#datadir <- \"/home/kln/projects/human_futures/data/sandbox\"\nhf.cor <- Corpus(DirSource(datadir, encoding  = \"UTF-8\"), readerControl = list(language=\"PlainTextDocument\"))\n\n# import document names\nfilenames <- gsub(\"\\\\..*\",\"\",names(hf.cor))# load metadata instead\n\n# preprocess quick and dirty\nhf.cor <- tm_map(hf.cor, PlainTextDocument)\nhf.cor <- tm_map(hf.cor, removePunctuation)\nhf.cor <- tm_map(hf.cor, removeNumbers)\nhf.cor <- tm_map(hf.cor, content_transformer(tolower))\nhf.cor <- tm_map(hf.cor, removeWords, stopwords(\"english\"))\nhf.cor <- tm_map(hf.cor, stemDocument)\nhf.cor <- tm_map(hf.cor, stripWhitespace)\nhf.cor <- tm_map(hf.cor, PlainTextDocument)\n\n## import class and type information (keywords)\nclass.df <- read.csv(\"/home/kln/projects/human_futures/keywords/keywords.csv\")\ntypes.v <- tolower(unlist(lapply(class.df[,3],as.character),use.names=FALSE))\n\n# remove whitespace and change underscore\ntypes.v <- gsub(\" \",\"\",types.v)\ntypes.v <- gsub(\"_\",\" \",types.v)\n\n# stem\nlibrary(SnowballC)\ntypes.stem.v <- wordStem(types.v,'english')\n\n\n## vector space (matrix)\nhf.dtm <- DocumentTermMatrix(hf.cor)\n#hf.dtm <- DocumentTermMatrix(hf.cor, control=list(tokenize = NGramTokenizer))\nhf.mat <- as.matrix(hf.dtm)\nrownames(hf.mat) <- filenames \nrm('filenames','datadir')\n\n# save\nsave.image(file = \"/home/kln/projects/human_futures/data/hf_corpus.RData\")\n\n## build feature space from vector space\nrm(list = ls())\nload(\"/home/kln/projects/human_futures/data/hf_corpus.RData\")\n\n# term dimensions\nterms.v <- hf.dtm$dimnames$Terms\n\n# identify keywords present in vector space\nis.empty <- function(x) return(length(x) == 0)\nidx.v <- numeric()\nfor(i in 1:length(types.stem.v)){\n  tmp <- which(terms.v == types.stem.v[i])\n  if(is.empty(tmp)){\n    idx.v[i] = NA\n  }else{\n    idx.v[i] = tmp\n  }\n}\n\n# update types and terms index by removing NA types \nmeta_idx.v <- !is.na(idx.v)# for accessing relevant keywords in original metadata\ntypes.stem.v <- types.stem.v[meta_idx.v]# features present in vector space\nidx.v <- idx.v[!is.na(idx.v)]# feature indices in vector space\n# feature space: reduce vector space\nfeature.mat = hf.mat[,idx.v]\nfeature.class.df <- class.df[meta_idx.v,]\n# use non-stemmed keywords as feature names \ncolnames(feature.mat) <- types.v[meta_idx.v]\n\n## clean up and save\nrm(list = setdiff(ls(), c(\"feature.mat\",\"feature.class.df\",\"meta_idx.v\")))\n# update save file\nresave <- function(..., list = character(), file) {\n  previous  <- load(file)\n  var.names <- c(list, as.character(substitute(list(...)))[-1L])\n  for (var in var.names) assign(var, get(var, envir = parent.frame()))\n  save(list = unique(c(previous, var.names)), file = file)\n}\n\nresave(\"feature.mat\",\"feature.class.df\",\"meta_idx.v\", file =  \"hf_corpus.RData\")",
    "created" : 1480234626277.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1944895559",
    "id" : "D04EF42B",
    "lastKnownWriteTime" : 1480243153,
    "last_content_update" : 1480243153819,
    "path" : "~/projects/human_futures/code/R/feature_space.R",
    "project_path" : "feature_space.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}